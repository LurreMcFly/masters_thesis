{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensemble import Ensemble_LinearRegression\n",
    "from meta_model import FSSN\n",
    "from active_anomaly_detector import AAD\n",
    "from utils import *\n",
    "from utils_plotting import *\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WINDOW_SIZE   = 40\n",
    "MIN_WINDOW_SIZE   = 5\n",
    "NUM_MEMBERS       = 50\n",
    "TRAIN_WINDOW_SIZE = 100\n",
    "MEAN_IMPUTE_RATE  = 0.2\n",
    "UPDATE_PROP       = 0.2\n",
    "targets_to_keep   = None\n",
    "query_frequency   = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load 20th Yahoo series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "df = load_data_yahoo(n)\n",
    "\n",
    "#Normalize data\n",
    "mu, s = df['value'].mean(), df['value'].std()\n",
    "df['value'] = (df['value'] - mu)/s\n",
    "\n",
    "#Generate a sliding window\n",
    "df = generate_sliding_window(df, window_size=MAX_WINDOW_SIZE, anomaly_window=False)\n",
    "\n",
    "#Slit into training and test\n",
    "train_df, test_df = train_test_split(df, p=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns in data frame we want to use\n",
    "train_cols = df.columns[-(MAX_WINDOW_SIZE):]\n",
    "\n",
    "#Training data \n",
    "x_train = train_df[train_cols].to_numpy()\n",
    "x_test = test_df[train_cols].to_numpy()\n",
    "\n",
    "#Targets\n",
    "y_train = train_df['lag0'].to_numpy()\n",
    "y_test = test_df['lag0'].to_numpy()\n",
    "\n",
    "#True anomaly values\n",
    "y_train_anomalies = train_df[['anomaly']].to_numpy().flatten()\n",
    "y_test_anomalies = test_df[['anomaly']].to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at the series (train and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_anomaly_series(train_df, column='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_anomaly_series(test_df, column='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "This function is in `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss(mm_outputs, target, score_x, score_x_prev, q_tau=1., lambda_prior=1.):\n",
    "    \"\"\"\n",
    "    Prepares the loss to update the meta model\n",
    "    \n",
    "    Calculates the losses:\n",
    "        Active Anomaly Detection loss: l_aad = max(0, y(q-score(x_t))) + max(0, y(score(x_t-1)-score(x_t)))\n",
    "        Prior loss:                    l_prior = ensemble_prior * log(p) + (1-ensemble_prior) * log(p)\n",
    "        Meta Model Loss:               l_mm = l_aad + lambda_prior * l_prior\n",
    "        \n",
    "    Args:\n",
    "        mm_outputs:     output from meta model\n",
    "        target:         labeled targets\n",
    "        q_tau:          threshold\n",
    "        score_x:        anomaly score at current time step\n",
    "        score_x_prev:   anomaly score at previous time step\n",
    "        ensemble_prior: prior for ensemble weights ex. [1/M or 1/sqrt(M)]\n",
    "        lambda_prior:   constant for amount of weight on l_prior\n",
    "    \"\"\"\n",
    "    if len(target):\n",
    "        #number of assigned labels\n",
    "        n_labels = len(target)\n",
    "\n",
    "        # If n_labels == 0, no labels have been assigned -> l_add = 0\n",
    "        y_ = torch.tensor(list(target.values()))\n",
    "        \n",
    "        l_aad = torch.mean(torch.max(torch.zeros(n_labels, dtype=float), y_ * (q_tau - score_x))) + \\\n",
    "                torch.mean(torch.max(torch.zeros(n_labels, dtype=float), y_ * (score_x_prev - score_x)))\n",
    "        \n",
    "    else:\n",
    "        l_aad = torch.tensor([0])\n",
    "        \n",
    "    #calculates ensemble weighting prior\n",
    "    ensemble_prior = torch.ones(mm_outputs.shape)/mm_outputs.shape[1]\n",
    "    \n",
    "    l_prior = F.binary_cross_entropy(mm_outputs, ensemble_prior, reduction='mean')\n",
    "    \n",
    "    l_mm = torch.sum(l_aad) + lambda_prior * torch.sum(l_prior)\n",
    "    return l_mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iniate Ensemble and Meta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_dict = {'LinearRegression':[x for x in np.random.randint(low=MIN_WINDOW_SIZE, high=MAX_WINDOW_SIZE, size=NUM_MEMBERS)]}\n",
    "ens = Ensemble_LinearRegression(ensemble_dict)\n",
    "\n",
    "meta_model = FSSN(MAX_WINDOW_SIZE, NUM_MEMBERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(meta_model.parameters(), lr=0.01, weight_decay=0)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aad = AAD(ens, meta_model, optimizer=optimizer, scheduler=scheduler, query_frequency=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aad.fit(x_train, y_train,\n",
    "        y_train_anomalies, \n",
    "        train_df, \n",
    "        window_size=TRAIN_WINDOW_SIZE, \n",
    "        mean_impute_rate=MEAN_IMPUTE_RATE, \n",
    "        update_prop=UPDATE_PROP,\n",
    "        plot=False,\n",
    "        print_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aad.predict(x_test, y_test,\n",
    "            y_test_anomalies,\n",
    "            test_df,\n",
    "            window_size=TRAIN_WINDOW_SIZE, \n",
    "            mean_impute_rate=MEAN_IMPUTE_RATE, \n",
    "            update_prop=UPDATE_PROP,\n",
    "            plot=False,\n",
    "            print_metrics=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
